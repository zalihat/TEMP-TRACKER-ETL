# Base image with OpenJDK 11
FROM openjdk:11

# Set environment variables
ENV SPARK_VERSION=3.5.4
ENV HADOOP_VERSION=3
ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$PATH"

# Install dependencies
RUN apt-get update && apt-get install -y curl tar bash procps && \
    rm -rf /var/lib/apt/lists/*

# Download and install Apache Spark
RUN curl -fsSL https://downloads.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz | tar -xz -C /opt && \
    mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark

# Set work directory
WORKDIR /opt/spark

# Expose ports (Master UI, Worker UI, Cluster Communication)
EXPOSE 8081 7077

# Default command
CMD ["bin/spark-class", "org.apache.spark.deploy.master.Master"]
