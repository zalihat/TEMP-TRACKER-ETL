[2025-02-01T19:27:44.045+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:27:44.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:27:44.055+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:27:44.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:27:44.093+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:27:44.079+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:27:44.094+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:27:44.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.122 seconds
[2025-02-01T19:28:14.438+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:28:14.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:28:14.443+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:28:14.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:28:14.457+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:28:14.454+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:28:14.459+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:28:14.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-02-01T19:51:15.152+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:51:15.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:51:15.161+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:51:15.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:51:15.208+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:51:15.193+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:51:15.209+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:51:15.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.134 seconds
[2025-02-01T19:51:45.411+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:51:45.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:51:45.417+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:51:45.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:51:45.435+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:51:45.431+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:51:45.436+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:51:45.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.065 seconds
[2025-02-01T19:52:15.807+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:52:15.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:52:15.811+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:15.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:52:15.826+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:15.823+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:52:15.827+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:52:15.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-02-01T19:52:46.073+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:52:46.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:52:46.077+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:46.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:52:46.092+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:46.088+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:52:46.093+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:52:46.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-02-01T19:53:16.283+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:53:16.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:53:16.287+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:16.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:53:16.303+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:16.298+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:53:16.304+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:53:16.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-02-01T19:53:46.458+0000] {processor.py:186} INFO - Started process (PID=393) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:53:46.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:53:46.463+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:46.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:53:46.480+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:46.475+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:53:46.481+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:53:46.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-02-01T19:54:16.595+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:54:16.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:54:16.599+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:16.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:54:16.615+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:16.610+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:54:16.616+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:54:16.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-02-01T19:54:46.788+0000] {processor.py:186} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:54:46.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:54:46.792+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:46.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:54:46.806+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:46.802+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:54:46.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:54:46.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.047 seconds
[2025-02-01T19:55:16.910+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:55:16.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:55:16.915+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:16.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:55:16.930+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:16.926+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:55:16.931+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:55:16.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.047 seconds
[2025-02-01T19:55:47.105+0000] {processor.py:186} INFO - Started process (PID=501) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:55:47.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:55:47.109+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:47.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:55:47.124+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:47.120+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:55:47.125+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:55:47.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-02-01T19:56:17.224+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:56:17.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:56:17.228+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:17.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:56:17.244+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:17.241+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:56:17.245+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:56:17.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-02-01T19:57:57.328+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T19:57:57.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T19:57:57.339+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:57:57.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:57:57.356+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:57:57.351+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T19:57:57.357+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T19:57:57.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.068 seconds
[2025-02-01T20:00:15.306+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:00:15.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:00:15.310+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:00:15.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:00:15.324+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:00:15.321+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:00:15.326+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:00:15.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.056 seconds
[2025-02-01T20:01:35.891+0000] {processor.py:186} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:01:35.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:01:35.895+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:35.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:01:35.914+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:35.910+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:01:35.915+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:01:35.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.062 seconds
[2025-02-01T20:02:06.123+0000] {processor.py:186} INFO - Started process (PID=626) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:02:06.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:02:06.128+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:06.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:02:06.145+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:06.140+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:02:06.146+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:02:06.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.063 seconds
[2025-02-01T20:02:36.345+0000] {processor.py:186} INFO - Started process (PID=633) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:02:36.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:02:36.350+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:36.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:02:36.366+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:36.362+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:02:36.368+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:02:36.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.059 seconds
[2025-02-01T20:03:06.671+0000] {processor.py:186} INFO - Started process (PID=640) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:03:06.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:03:06.675+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:06.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:03:06.692+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:06.687+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:03:06.693+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:03:06.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.062 seconds
[2025-02-01T20:03:37.414+0000] {processor.py:186} INFO - Started process (PID=647) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:03:37.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:03:37.418+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:37.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:03:37.431+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:37.428+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:03:37.432+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:03:37.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-02-01T20:04:07.643+0000] {processor.py:186} INFO - Started process (PID=654) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:04:07.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:04:07.647+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:07.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:04:07.664+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:07.660+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:04:07.665+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:04:07.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.065 seconds
[2025-02-01T20:04:39.346+0000] {processor.py:186} INFO - Started process (PID=673) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:04:39.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:04:39.350+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:39.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:04:39.363+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:39.359+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:04:39.364+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:04:39.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.056 seconds
[2025-02-01T20:05:10.132+0000] {processor.py:186} INFO - Started process (PID=680) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:05:10.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:05:10.137+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:05:10.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:05:10.152+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:05:10.148+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:05:10.153+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:05:10.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.057 seconds
[2025-02-01T20:05:40.582+0000] {processor.py:186} INFO - Started process (PID=687) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:05:40.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:05:40.586+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:05:40.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:05:40.599+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:05:40.596+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:05:40.601+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:05:40.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.056 seconds
[2025-02-01T20:06:10.740+0000] {processor.py:186} INFO - Started process (PID=694) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:06:10.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:06:10.746+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:10.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:06:10.765+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:10.760+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:06:10.766+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:06:10.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.070 seconds
[2025-02-01T20:06:40.924+0000] {processor.py:186} INFO - Started process (PID=701) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:06:40.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:06:40.929+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:40.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:06:40.949+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:40.944+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:06:40.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:06:41.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.146 seconds
[2025-02-01T20:07:12.153+0000] {processor.py:186} INFO - Started process (PID=708) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:07:12.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:07:12.157+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:12.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:07:12.174+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:12.169+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:07:12.176+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:07:12.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.062 seconds
[2025-02-01T20:07:42.690+0000] {processor.py:186} INFO - Started process (PID=715) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:07:42.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:07:42.695+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:42.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:07:42.711+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:42.706+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:07:42.712+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:07:42.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.057 seconds
[2025-02-01T20:08:13.707+0000] {processor.py:186} INFO - Started process (PID=722) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:08:13.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:08:13.711+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:08:13.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:08:13.729+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:08:13.724+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:08:13.730+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:08:13.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.064 seconds
[2025-02-01T20:11:39.092+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:11:39.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:11:39.103+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:11:39.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:11:39.192+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:11:39.140+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:11:39.204+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:11:39.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.263 seconds
[2025-02-01T20:14:40.018+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:14:40.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:14:40.025+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:40.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:14:40.050+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:40.044+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:14:40.052+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:14:40.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.108 seconds
[2025-02-01T20:29:48.082+0000] {processor.py:186} INFO - Started process (PID=752) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:29:48.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:29:48.091+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:29:48.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:29:48.109+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:29:48.104+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:29:48.111+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:29:48.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.082 seconds
[2025-02-01T20:30:22.498+0000] {processor.py:186} INFO - Started process (PID=759) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:30:22.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:30:22.724+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:22.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:30:23.467+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:23.212+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:30:23.509+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:30:25.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 3.647 seconds
[2025-02-01T20:45:32.775+0000] {processor.py:186} INFO - Started process (PID=766) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:45:32.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:45:32.780+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:45:32.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:45:32.817+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:45:32.811+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:45:32.819+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:45:32.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.118 seconds
[2025-02-01T20:46:12.467+0000] {processor.py:186} INFO - Started process (PID=773) to work on /opt/airflow/dags/spark_dag.py
[2025-02-01T20:46:12.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-02-01T20:46:12.714+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:46:12.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:46:13.388+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:46:13.155+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-02-01T20:46:13.437+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-02-01T20:46:15.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 4.073 seconds
