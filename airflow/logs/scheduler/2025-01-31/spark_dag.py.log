[2025-01-31T19:13:38.811+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:13:38.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:13:38.816+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:38.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:13:38.865+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:13:39.143+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.142+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:pyspark_example
[2025-01-31T19:13:39.162+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.162+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:pyspark_example
[2025-01-31T19:13:39.174+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.174+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:pyspark_example
[2025-01-31T19:13:39.186+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.186+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:pyspark_example
[2025-01-31T19:13:39.197+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.197+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:pyspark_example
[2025-01-31T19:13:39.208+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.208+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:pyspark_example
[2025-01-31T19:13:39.230+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.229+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:pyspark_example
[2025-01-31T19:13:39.231+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:13:39.263+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.263+0000] {dag.py:3262} INFO - Creating ORM DAG for pyspark_example
[2025-01-31T19:13:39.292+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:13:39.292+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-30 00:00:00+00:00, run_after=2025-01-31 00:00:00+00:00
[2025-01-31T19:13:39.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.531 seconds
[2025-01-31T19:14:09.772+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:14:09.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:14:09.778+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:14:09.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:14:09.810+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:14:09.840+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:14:09.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:14:09.866+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:14:09.866+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-30 00:00:00+00:00, run_after=2025-01-31 00:00:00+00:00
[2025-01-31T19:14:09.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.124 seconds
[2025-01-31T19:14:40.279+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:14:40.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:14:40.283+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:14:40.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:14:40.300+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:14:40.331+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:14:40.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:14:40.362+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:14:40.362+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:14:40.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.117 seconds
[2025-01-31T19:15:10.478+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:15:10.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:15:10.482+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:15:10.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:15:10.498+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:15:10.526+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:15:10.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:15:10.555+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:15:10.554+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:15:10.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.112 seconds
[2025-01-31T19:15:40.858+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:15:40.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:15:40.862+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:15:40.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:15:40.882+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:15:40.919+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:15:40.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:15:40.954+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:15:40.954+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:15:40.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.130 seconds
[2025-01-31T19:16:11.097+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:16:11.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:16:11.101+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:16:11.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:16:11.116+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:16:11.147+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:16:11.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:16:11.183+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:16:11.182+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:16:11.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.117 seconds
[2025-01-31T19:16:41.388+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:16:41.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:16:41.392+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:16:41.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:16:41.408+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:16:41.438+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:16:41.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:16:41.466+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:16:41.466+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:16:41.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.107 seconds
[2025-01-31T19:17:11.600+0000] {processor.py:186} INFO - Started process (PID=422) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:17:11.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:17:11.605+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:17:11.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:17:11.621+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:17:11.651+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:17:11.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:17:11.676+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:17:11.676+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:17:11.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.104 seconds
[2025-01-31T19:17:41.812+0000] {processor.py:186} INFO - Started process (PID=449) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:17:41.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:17:41.816+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:17:41.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:17:41.833+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:17:41.864+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:17:41.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:17:41.897+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:17:41.897+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:17:41.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.116 seconds
[2025-01-31T19:18:12.082+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:18:12.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:18:12.087+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:18:12.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:18:12.105+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:18:12.139+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:18:12.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:18:12.174+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:18:12.174+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:18:12.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.136 seconds
[2025-01-31T19:18:43.201+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:18:43.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:18:43.205+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:18:43.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:18:43.222+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:18:43.251+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:18:43.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:18:43.278+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:18:43.278+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:18:43.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.109 seconds
[2025-01-31T19:19:13.378+0000] {processor.py:186} INFO - Started process (PID=548) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:19:13.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:19:13.384+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:19:13.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:19:13.412+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:19:13.447+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:19:13.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:19:13.480+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:19:13.480+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:19:13.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.137 seconds
[2025-01-31T19:19:43.638+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:19:43.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:19:43.642+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:19:43.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:19:43.659+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:19:43.687+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:19:43.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:19:43.712+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:19:43.712+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:19:43.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.099 seconds
[2025-01-31T19:20:13.881+0000] {processor.py:186} INFO - Started process (PID=602) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:20:13.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:20:13.886+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:20:13.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:20:13.903+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:20:13.936+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:20:13.936+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:20:13.966+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:20:13.966+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:20:13.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.117 seconds
[2025-01-31T19:20:44.126+0000] {processor.py:186} INFO - Started process (PID=629) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:20:44.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:20:44.129+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:20:44.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:20:44.148+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:20:44.181+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:20:44.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:20:44.210+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:20:44.210+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:20:44.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.117 seconds
[2025-01-31T19:21:14.320+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:21:14.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:21:14.324+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:21:14.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:21:14.345+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:21:14.376+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:21:14.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:21:14.406+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:21:14.406+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:21:14.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.119 seconds
[2025-01-31T19:21:44.654+0000] {processor.py:186} INFO - Started process (PID=683) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:21:44.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:21:44.658+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:21:44.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:21:44.675+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:21:44.710+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:21:44.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:21:44.738+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:21:44.737+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:21:44.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.113 seconds
[2025-01-31T19:22:14.840+0000] {processor.py:186} INFO - Started process (PID=710) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:22:14.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:22:14.844+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:22:14.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:22:14.861+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:22:14.893+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:22:14.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:22:14.921+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:22:14.921+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:22:14.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.109 seconds
[2025-01-31T19:22:45.357+0000] {processor.py:186} INFO - Started process (PID=737) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:22:45.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:22:45.363+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:22:45.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:22:45.381+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:22:45.414+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:22:45.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:22:45.443+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:22:45.443+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:22:45.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.123 seconds
[2025-01-31T19:23:15.593+0000] {processor.py:186} INFO - Started process (PID=764) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:23:15.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:23:15.597+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:23:15.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:23:15.618+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:23:15.654+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:23:15.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:23:15.697+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:23:15.697+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:23:15.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.138 seconds
[2025-01-31T19:23:45.883+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:23:45.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:23:45.887+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:23:45.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:23:45.906+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:23:45.943+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:23:45.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:23:45.990+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:23:45.989+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:23:46.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.143 seconds
[2025-01-31T19:24:16.122+0000] {processor.py:186} INFO - Started process (PID=818) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:24:16.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:24:16.126+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:24:16.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:24:16.143+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:24:16.174+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:24:16.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:24:16.203+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:24:16.203+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:24:16.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.112 seconds
[2025-01-31T19:24:46.424+0000] {processor.py:186} INFO - Started process (PID=845) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:24:46.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:24:46.429+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:24:46.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:24:46.445+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:24:46.475+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:24:46.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:24:46.502+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:24:46.502+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:24:46.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.106 seconds
[2025-01-31T19:26:38.865+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:26:38.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:26:38.872+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:26:38.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:26:38.892+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:26:38.957+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:26:38.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:26:38.995+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:26:38.995+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:26:39.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.171 seconds
[2025-01-31T19:27:09.513+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:27:09.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:27:09.519+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:27:09.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:27:09.552+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:27:09.587+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:27:09.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:27:09.619+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:27:09.619+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:27:09.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.138 seconds
[2025-01-31T19:27:39.927+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:27:39.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:27:39.931+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:27:39.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:27:39.953+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:27:39.999+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:27:39.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:27:40.043+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:27:40.043+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:27:40.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.146 seconds
[2025-01-31T19:28:10.527+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:28:10.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:28:10.531+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:28:10.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:28:10.547+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:28:10.578+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:28:10.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:28:10.605+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:28:10.605+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:28:10.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.107 seconds
[2025-01-31T19:28:41.173+0000] {processor.py:186} INFO - Started process (PID=323) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:28:41.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:28:41.177+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:28:41.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:28:41.199+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:28:41.249+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:28:41.249+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:28:41.293+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:28:41.292+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:28:41.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.155 seconds
[2025-01-31T19:29:11.570+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:29:11.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:29:11.576+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:29:11.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:29:11.600+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:29:11.632+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:29:11.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:29:11.660+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:29:11.659+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:29:11.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.127 seconds
[2025-01-31T19:29:41.750+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:29:41.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:29:41.755+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:29:41.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:29:41.775+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:29:41.807+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:29:41.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:29:41.838+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:29:41.837+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:29:41.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.120 seconds
[2025-01-31T19:30:12.065+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:30:12.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:30:12.073+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:30:12.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:30:12.101+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:30:12.155+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:30:12.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:30:12.193+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:30:12.192+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:30:12.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.180 seconds
[2025-01-31T19:30:43.074+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:30:43.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:30:43.081+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:30:43.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:30:43.101+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:30:43.135+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:30:43.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:30:43.163+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:30:43.163+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:30:43.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.119 seconds
[2025-01-31T19:31:13.282+0000] {processor.py:186} INFO - Started process (PID=467) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:31:13.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:31:13.288+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:31:13.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:31:13.306+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:31:13.339+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:31:13.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:31:13.368+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:31:13.368+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:31:13.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.118 seconds
[2025-01-31T19:31:43.627+0000] {processor.py:186} INFO - Started process (PID=494) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:31:43.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:31:43.631+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:31:43.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:31:43.652+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:31:43.687+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:31:43.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:31:43.719+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:31:43.718+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:31:43.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.125 seconds
[2025-01-31T19:32:14.096+0000] {processor.py:186} INFO - Started process (PID=522) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:32:14.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:32:14.101+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:32:14.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:32:14.123+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:32:14.163+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:32:14.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:32:14.194+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:32:14.193+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:32:14.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.133 seconds
[2025-01-31T19:32:44.363+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:32:44.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:32:44.368+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:32:44.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:32:44.390+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:32:44.430+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:32:44.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:32:44.464+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:32:44.464+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:32:44.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.139 seconds
[2025-01-31T19:33:14.662+0000] {processor.py:186} INFO - Started process (PID=576) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:33:14.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:33:14.667+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:33:14.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:33:14.686+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:33:14.723+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:33:14.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:33:14.768+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:33:14.768+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:33:14.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.139 seconds
[2025-01-31T19:33:44.908+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:33:44.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:33:44.913+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:33:44.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:33:44.937+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:33:44.978+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:33:44.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:33:45.012+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:33:45.012+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:33:45.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.144 seconds
[2025-01-31T19:34:15.106+0000] {processor.py:186} INFO - Started process (PID=642) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:34:15.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:34:15.111+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:34:15.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:34:15.128+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:34:15.168+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:34:15.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:34:15.201+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:34:15.200+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:34:15.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.125 seconds
[2025-01-31T19:34:45.268+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:34:45.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:34:45.275+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:34:45.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:34:45.295+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:34:45.328+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:34:45.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:34:45.361+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:34:45.360+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:34:45.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.128 seconds
[2025-01-31T19:35:15.717+0000] {processor.py:186} INFO - Started process (PID=693) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:35:15.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:35:15.721+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:35:15.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:35:15.742+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:35:15.779+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:35:15.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:35:15.812+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:35:15.812+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:35:15.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.129 seconds
[2025-01-31T19:35:46.752+0000] {processor.py:186} INFO - Started process (PID=720) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:35:46.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:35:46.757+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:35:46.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:35:46.776+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:35:46.810+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:35:46.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:35:46.840+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:35:46.839+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:35:46.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.123 seconds
[2025-01-31T19:36:56.084+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:36:56.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:36:56.089+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:36:56.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:36:56.107+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:36:56.190+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:36:56.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:36:56.276+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:36:56.275+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:36:56.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.243 seconds
[2025-01-31T19:37:26.696+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:37:26.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:37:26.701+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:37:26.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:37:26.721+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:37:26.753+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:37:26.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:37:26.789+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:37:26.789+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:37:26.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.131 seconds
[2025-01-31T19:37:56.910+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:37:56.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:37:56.915+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:37:56.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:37:56.934+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:37:56.968+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:37:56.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:37:56.997+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:37:56.996+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:37:57.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.120 seconds
[2025-01-31T19:38:27.094+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:38:27.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:38:27.099+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:38:27.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:38:27.119+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:38:27.157+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:38:27.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:38:27.193+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:38:27.192+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:38:27.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.136 seconds
[2025-01-31T19:39:03.282+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:39:03.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:39:03.287+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:39:03.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:39:03.302+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:39:03.355+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:39:03.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:39:03.383+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:39:03.383+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:39:03.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.141 seconds
[2025-01-31T19:39:33.580+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:39:33.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:39:33.585+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:39:33.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:39:33.607+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:39:33.638+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:39:33.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:39:33.667+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:39:33.667+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:39:33.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.119 seconds
[2025-01-31T19:40:03.858+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:40:03.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:40:03.862+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:40:03.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:40:03.883+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:40:03.918+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:40:03.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:40:03.948+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:40:03.948+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:40:03.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.123 seconds
[2025-01-31T19:40:34.088+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:40:34.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:40:34.093+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:40:34.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:40:34.110+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:40:34.143+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:40:34.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:40:34.173+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:40:34.172+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:40:34.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.117 seconds
[2025-01-31T19:41:04.326+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:41:04.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:41:04.329+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:41:04.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:41:04.345+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:41:04.373+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:41:04.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:41:04.405+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:41:04.405+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:41:04.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.113 seconds
[2025-01-31T19:41:34.770+0000] {processor.py:186} INFO - Started process (PID=369) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:41:34.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:41:34.774+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:41:34.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:41:34.793+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:41:34.821+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:41:34.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:41:34.847+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:41:34.847+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:41:34.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.104 seconds
[2025-01-31T19:42:05.000+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:42:05.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:42:05.008+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:42:05.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:42:05.031+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:42:05.070+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:42:05.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:42:05.105+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:42:05.105+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:42:05.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.145 seconds
[2025-01-31T19:42:35.433+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:42:35.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:42:35.437+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:42:35.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:42:35.453+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:42:35.484+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:42:35.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:42:35.512+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:42:35.512+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:42:35.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.112 seconds
[2025-01-31T19:43:05.719+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:43:05.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:43:05.723+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:43:05.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:43:05.740+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:43:05.774+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:43:05.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:43:05.807+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:43:05.807+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:43:05.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.121 seconds
[2025-01-31T19:43:35.964+0000] {processor.py:186} INFO - Started process (PID=477) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:43:35.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:43:35.969+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:43:35.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:43:35.983+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:43:36.018+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:43:36.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:43:36.049+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:43:36.049+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:43:36.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.117 seconds
[2025-01-31T19:44:06.271+0000] {processor.py:186} INFO - Started process (PID=504) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:44:06.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:44:06.276+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:44:06.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:44:06.296+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:44:06.335+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:44:06.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:44:06.368+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:44:06.367+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:44:06.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.128 seconds
[2025-01-31T19:44:36.517+0000] {processor.py:186} INFO - Started process (PID=531) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:44:36.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:44:36.521+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:44:36.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:44:36.541+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:44:36.572+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:44:36.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:44:36.598+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:44:36.598+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:44:36.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.112 seconds
[2025-01-31T19:45:06.722+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:45:06.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:45:06.727+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:45:06.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:45:06.745+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:45:06.775+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:45:06.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:45:06.801+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:45:06.800+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:45:06.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.107 seconds
[2025-01-31T19:45:36.909+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:45:36.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:45:36.915+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:45:36.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:45:36.934+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:45:36.963+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:45:36.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:45:36.988+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:45:36.988+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:45:37.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.109 seconds
[2025-01-31T19:46:07.062+0000] {processor.py:186} INFO - Started process (PID=630) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:46:07.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:46:07.067+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:46:07.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:46:07.088+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:46:07.117+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:46:07.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:46:07.142+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:46:07.142+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:46:07.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.110 seconds
[2025-01-31T19:46:37.291+0000] {processor.py:186} INFO - Started process (PID=657) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:46:37.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:46:37.295+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:46:37.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:46:37.311+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:46:37.338+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:46:37.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:46:37.367+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:46:37.366+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:46:37.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.114 seconds
[2025-01-31T19:47:07.523+0000] {processor.py:186} INFO - Started process (PID=684) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:47:07.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:47:07.529+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:47:07.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:47:07.558+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:47:07.591+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:47:07.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:47:07.617+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:47:07.617+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:47:07.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.125 seconds
[2025-01-31T19:47:37.775+0000] {processor.py:186} INFO - Started process (PID=711) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:47:37.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:47:37.779+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:47:37.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:47:37.795+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:47:37.826+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:47:37.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:47:37.850+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:47:37.850+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:47:37.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.104 seconds
[2025-01-31T19:48:08.902+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:48:08.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:48:08.906+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:48:08.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:48:08.923+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:48:08.953+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:48:08.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:48:08.981+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:48:08.981+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:48:09.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.110 seconds
[2025-01-31T19:48:39.113+0000] {processor.py:186} INFO - Started process (PID=765) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:48:39.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:48:39.118+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:48:39.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:48:39.136+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:48:39.167+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:48:39.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:48:39.195+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:48:39.194+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:48:39.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.113 seconds
[2025-01-31T19:49:09.317+0000] {processor.py:186} INFO - Started process (PID=792) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:49:09.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:49:09.322+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:49:09.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:49:09.341+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:49:09.378+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:49:09.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:49:09.413+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:49:09.412+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:49:09.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.130 seconds
[2025-01-31T19:49:39.505+0000] {processor.py:186} INFO - Started process (PID=819) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:49:39.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:49:39.510+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:49:39.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:49:39.527+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:49:39.558+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:49:39.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:49:39.587+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:49:39.587+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:49:39.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.113 seconds
[2025-01-31T19:50:09.690+0000] {processor.py:186} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:50:09.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:50:09.695+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:50:09.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:50:09.713+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:50:09.748+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:50:09.747+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:50:09.780+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:50:09.780+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:50:09.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.128 seconds
[2025-01-31T19:50:39.882+0000] {processor.py:186} INFO - Started process (PID=873) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:50:39.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:50:39.886+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:50:39.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:50:39.904+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:50:39.936+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:50:39.936+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:50:39.965+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:50:39.965+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:50:39.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.113 seconds
[2025-01-31T19:51:10.226+0000] {processor.py:186} INFO - Started process (PID=900) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:51:10.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:51:10.231+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:51:10.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:51:10.249+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:51:10.282+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:51:10.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:51:10.310+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:51:10.310+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:51:10.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.117 seconds
[2025-01-31T19:51:40.420+0000] {processor.py:186} INFO - Started process (PID=927) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:51:40.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:51:40.425+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:51:40.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:51:40.442+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:51:40.474+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:51:40.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:51:40.503+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:51:40.503+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:51:40.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.115 seconds
[2025-01-31T19:52:10.624+0000] {processor.py:186} INFO - Started process (PID=954) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:52:10.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:52:10.629+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:52:10.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:52:10.646+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:52:10.678+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:52:10.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:52:10.708+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:52:10.708+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:52:10.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.114 seconds
[2025-01-31T19:52:41.735+0000] {processor.py:186} INFO - Started process (PID=981) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:52:41.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:52:41.739+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:52:41.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:52:41.756+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:52:41.788+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:52:41.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:52:41.816+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:52:41.816+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:52:41.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.107 seconds
[2025-01-31T19:53:11.923+0000] {processor.py:186} INFO - Started process (PID=1008) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:53:11.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:53:11.928+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:53:11.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:53:11.944+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:53:11.981+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:53:11.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:53:12.008+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:53:12.008+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:53:12.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.111 seconds
[2025-01-31T19:53:42.282+0000] {processor.py:186} INFO - Started process (PID=1035) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:53:42.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:53:42.286+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:53:42.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:53:42.304+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:53:42.342+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:53:42.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:53:42.374+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:53:42.374+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:53:42.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.129 seconds
[2025-01-31T19:54:12.542+0000] {processor.py:186} INFO - Started process (PID=1062) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:54:12.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:54:12.546+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:54:12.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:54:12.563+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:54:12.591+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:54:12.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:54:12.617+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:54:12.617+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:54:12.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.106 seconds
[2025-01-31T19:54:42.724+0000] {processor.py:186} INFO - Started process (PID=1089) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:54:42.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:54:42.729+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:54:42.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:54:42.748+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:54:42.777+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:54:42.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:54:42.804+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:54:42.804+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:54:42.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.110 seconds
[2025-01-31T19:55:13.162+0000] {processor.py:186} INFO - Started process (PID=1116) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:55:13.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:55:13.166+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:55:13.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:55:13.185+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:55:13.217+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:55:13.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:55:13.242+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:55:13.242+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:55:13.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.109 seconds
[2025-01-31T19:55:43.527+0000] {processor.py:186} INFO - Started process (PID=1121) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:55:43.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:55:43.531+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:55:43.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:55:43.547+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:55:43.577+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:55:43.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:55:43.606+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:55:43.605+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:55:43.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.107 seconds
[2025-01-31T19:56:13.733+0000] {processor.py:186} INFO - Started process (PID=1148) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:56:13.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:56:13.738+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:56:13.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:56:13.756+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:56:13.788+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:56:13.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:56:13.816+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:56:13.816+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:56:13.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.123 seconds
[2025-01-31T19:56:43.924+0000] {processor.py:186} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:56:43.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:56:43.928+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:56:43.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:56:43.945+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:56:43.973+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:56:43.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:56:43.999+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:56:43.998+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:56:44.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.107 seconds
[2025-01-31T19:57:14.169+0000] {processor.py:186} INFO - Started process (PID=1202) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:57:14.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:57:14.175+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:57:14.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:57:14.193+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:57:14.227+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:57:14.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:57:14.260+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:57:14.260+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:57:14.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.125 seconds
[2025-01-31T19:57:44.513+0000] {processor.py:186} INFO - Started process (PID=1229) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:57:44.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:57:44.519+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:57:44.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:57:44.536+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:57:44.626+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:57:44.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:57:44.660+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:57:44.659+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:57:44.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.176 seconds
[2025-01-31T19:58:15.042+0000] {processor.py:186} INFO - Started process (PID=1256) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:58:15.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:58:15.046+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:58:15.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:58:15.063+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:58:15.096+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:58:15.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:58:15.126+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:58:15.125+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:58:15.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.115 seconds
[2025-01-31T19:58:45.334+0000] {processor.py:186} INFO - Started process (PID=1283) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:58:45.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:58:45.340+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:58:45.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:58:45.359+0000] {processor.py:925} INFO - DAG(s) 'pyspark_example' retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:58:45.401+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:58:45.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-31T19:58:45.439+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:58:45.439+0000] {dag.py:4180} INFO - Setting next_dagrun for pyspark_example to 2025-01-31 00:00:00+00:00, run_after=2025-02-01 00:00:00+00:00
[2025-01-31T19:58:45.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.148 seconds
[2025-01-31T19:59:02.414+0000] {processor.py:186} INFO - Started process (PID=1310) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:59:02.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:59:02.419+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:59:02.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:59:02.435+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:59:02.433+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T19:59:02.436+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:59:02.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T19:59:42.222+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T19:59:42.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T19:59:42.227+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:59:42.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:59:42.243+0000] {logging_mixin.py:190} INFO - [2025-01-31T19:59:42.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T19:59:42.244+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T19:59:42.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.059 seconds
[2025-01-31T20:00:12.537+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:00:12.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:00:12.540+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:00:12.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:00:12.554+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:00:12.550+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:00:12.555+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:00:12.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.055 seconds
[2025-01-31T20:00:42.687+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:00:42.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:00:42.689+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:00:42.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:00:42.704+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:00:42.700+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:00:42.705+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:00:42.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.046 seconds
[2025-01-31T20:01:12.839+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:01:12.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:01:12.841+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:01:12.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:01:12.856+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:01:12.852+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:01:12.858+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:01:12.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.054 seconds
[2025-01-31T20:01:42.946+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:01:42.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:01:42.950+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:01:42.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:01:42.968+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:01:42.964+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:01:42.969+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:01:42.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.059 seconds
[2025-01-31T20:02:13.330+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:02:13.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:02:13.333+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:02:13.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:02:13.348+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:02:13.345+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:02:13.349+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:02:13.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.046 seconds
[2025-01-31T20:02:43.447+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:02:43.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:02:43.449+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:02:43.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:02:43.464+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:02:43.460+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:02:43.465+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:02:43.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:03:13.617+0000] {processor.py:186} INFO - Started process (PID=393) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:03:13.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:03:13.621+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:03:13.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:03:13.635+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:03:13.631+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:03:13.636+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:03:13.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-01-31T20:03:43.764+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:03:43.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:03:43.768+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:03:43.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:03:43.781+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:03:43.777+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:03:43.782+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:03:43.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:04:13.873+0000] {processor.py:186} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:04:13.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:04:13.876+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:04:13.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:04:13.889+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:04:13.886+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:04:13.890+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:04:13.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.045 seconds
[2025-01-31T20:04:44.114+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:04:44.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:04:44.117+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:04:44.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:04:44.131+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:04:44.127+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:04:44.132+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:04:44.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T20:05:14.346+0000] {processor.py:186} INFO - Started process (PID=501) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:05:14.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:05:14.350+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:05:14.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:05:14.363+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:05:14.360+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:05:14.364+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:05:14.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T20:05:44.557+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:05:44.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:05:44.560+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:05:44.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:05:44.573+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:05:44.570+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:05:44.575+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:05:44.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T20:06:14.704+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:06:14.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:06:14.707+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:06:14.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:06:14.721+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:06:14.717+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:06:14.722+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:06:14.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:06:45.009+0000] {processor.py:186} INFO - Started process (PID=582) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:06:45.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:06:45.012+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:06:45.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:06:45.026+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:06:45.022+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:06:45.027+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:06:45.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:07:15.229+0000] {processor.py:186} INFO - Started process (PID=609) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:07:15.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:07:15.231+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:07:15.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:07:15.245+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:07:15.241+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:07:15.246+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:07:15.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T20:07:45.422+0000] {processor.py:186} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:07:45.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:07:45.425+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:07:45.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:07:45.437+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:07:45.434+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:07:45.439+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:07:45.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.043 seconds
[2025-01-31T20:08:15.642+0000] {processor.py:186} INFO - Started process (PID=663) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:08:15.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:08:15.644+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:08:15.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:08:15.658+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:08:15.654+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:08:15.659+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:08:15.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:08:45.868+0000] {processor.py:186} INFO - Started process (PID=690) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:08:45.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:08:45.870+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:08:45.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:08:45.885+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:08:45.881+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:08:45.886+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:08:45.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.045 seconds
[2025-01-31T20:09:16.831+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:09:16.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:09:16.836+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:09:16.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:09:16.850+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:09:16.846+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:09:16.851+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:09:16.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.057 seconds
[2025-01-31T20:09:47.182+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:09:47.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:09:47.187+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:09:47.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:09:47.201+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:09:47.198+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:09:47.202+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:09:47.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-01-31T20:10:17.374+0000] {processor.py:186} INFO - Started process (PID=257) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:10:17.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:10:17.377+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:10:17.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:10:17.389+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:10:17.386+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:10:17.390+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:10:17.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.044 seconds
[2025-01-31T20:10:47.635+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:10:47.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:10:47.639+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:10:47.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:10:47.652+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:10:47.649+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:10:47.653+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:10:47.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T20:11:17.829+0000] {processor.py:186} INFO - Started process (PID=311) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:11:17.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:11:17.833+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:11:17.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:11:17.847+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:11:17.843+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:11:17.848+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:11:17.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.047 seconds
[2025-01-31T20:11:48.005+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:11:48.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:11:48.010+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:11:48.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:11:48.024+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:11:48.020+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:11:48.025+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:11:48.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:12:18.144+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:12:18.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:12:18.147+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:12:18.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:12:18.161+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:12:18.157+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:12:18.162+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:12:18.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T20:12:48.491+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:12:48.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:12:48.495+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:12:48.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:12:48.511+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:12:48.507+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:12:48.512+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:12:48.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-01-31T20:13:18.709+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:13:18.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:13:18.713+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:13:18.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:13:18.727+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:13:18.723+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:13:18.728+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:13:18.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:13:48.832+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:13:48.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:13:48.837+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:13:48.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:13:48.851+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:13:48.847+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:13:48.853+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:13:48.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:14:19.015+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:14:19.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:14:19.020+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:14:19.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:14:19.036+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:14:19.030+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:14:19.037+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:14:19.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.058 seconds
[2025-01-31T20:14:49.414+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:14:49.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:14:49.419+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:14:49.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:14:49.435+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:14:49.431+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:14:49.437+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:14:49.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.063 seconds
[2025-01-31T20:18:01.664+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:18:01.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:18:01.668+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:18:01.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:18:01.682+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:18:01.677+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:18:01.686+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:18:01.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:18:31.949+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:18:31.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:18:31.953+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:18:31.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:18:31.966+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:18:31.962+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:18:31.967+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:18:31.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:19:02.166+0000] {processor.py:186} INFO - Started process (PID=257) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:19:02.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:19:02.170+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:19:02.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:19:02.184+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:19:02.180+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:19:02.185+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:19:02.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:19:32.359+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:19:32.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:19:32.363+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:19:32.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:19:32.376+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:19:32.373+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:19:32.378+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:19:32.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T20:20:02.531+0000] {processor.py:186} INFO - Started process (PID=311) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:20:02.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:20:02.535+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:20:02.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:20:02.548+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:20:02.544+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:20:02.549+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:20:02.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:20:32.689+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:20:32.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:20:32.693+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:20:32.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:20:32.708+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:20:32.705+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:20:32.709+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:20:32.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T20:21:02.801+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:21:02.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:21:02.805+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:21:02.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:21:02.818+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:21:02.814+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:21:02.819+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:21:02.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:21:32.990+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:21:32.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:21:32.995+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:21:32.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:21:33.007+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:21:33.004+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:21:33.009+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:21:33.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:22:03.483+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:22:03.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:22:03.487+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:22:03.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:22:03.501+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:22:03.498+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:22:03.503+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:22:03.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-01-31T20:22:33.706+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:22:33.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:22:33.711+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:22:33.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:22:33.726+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:22:33.722+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:22:33.727+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:22:33.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.055 seconds
[2025-01-31T20:23:03.918+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:23:03.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:23:03.922+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:23:03.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:23:03.935+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:23:03.932+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:23:03.936+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:23:03.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T20:23:34.126+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:23:34.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:23:34.129+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:23:34.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:23:34.143+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:23:34.139+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:23:34.144+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:23:34.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:24:04.296+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:24:04.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:24:04.300+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:24:04.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:24:04.313+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:24:04.310+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:24:04.314+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:24:04.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T20:24:34.474+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:24:34.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:24:34.479+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:24:34.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:24:34.492+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:24:34.489+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:24:34.493+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:24:34.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-01-31T20:25:04.651+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:25:04.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:25:04.656+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:25:04.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:25:04.670+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:25:04.666+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:25:04.671+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:25:04.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:25:34.917+0000] {processor.py:186} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:25:34.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:25:34.921+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:25:34.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:25:34.935+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:25:34.931+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:25:34.936+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:25:34.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T20:26:05.112+0000] {processor.py:186} INFO - Started process (PID=635) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:26:05.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:26:05.116+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:26:05.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:26:05.129+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:26:05.126+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:26:05.131+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:26:05.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T20:26:35.291+0000] {processor.py:186} INFO - Started process (PID=662) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:26:35.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:26:35.295+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:26:35.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:26:35.308+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:26:35.305+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:26:35.309+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:26:35.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:27:05.486+0000] {processor.py:186} INFO - Started process (PID=689) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:27:05.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:27:05.490+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:27:05.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:27:05.505+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:27:05.501+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:27:05.507+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:27:05.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.054 seconds
[2025-01-31T20:27:35.751+0000] {processor.py:186} INFO - Started process (PID=716) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:27:35.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:27:35.757+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:27:35.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:27:35.770+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:27:35.767+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:27:35.772+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:27:35.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.057 seconds
[2025-01-31T20:28:06.015+0000] {processor.py:186} INFO - Started process (PID=743) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:28:06.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:28:06.020+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:28:06.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:28:06.037+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:28:06.032+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:28:06.039+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:28:06.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.059 seconds
[2025-01-31T20:28:36.222+0000] {processor.py:186} INFO - Started process (PID=770) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:28:36.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:28:36.227+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:28:36.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:28:36.242+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:28:36.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:28:36.244+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:28:36.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.057 seconds
[2025-01-31T20:29:06.394+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:29:06.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:29:06.399+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:29:06.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:29:06.417+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:29:06.412+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:29:06.418+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:29:06.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.072 seconds
[2025-01-31T20:29:36.708+0000] {processor.py:186} INFO - Started process (PID=824) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:29:36.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:29:36.712+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:29:36.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:29:36.727+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:29:36.723+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:29:36.728+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:29:36.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-01-31T20:30:06.986+0000] {processor.py:186} INFO - Started process (PID=851) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:30:06.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:30:06.990+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:30:06.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:30:07.006+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:30:07.002+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:30:07.008+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:30:07.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.060 seconds
[2025-01-31T20:30:37.192+0000] {processor.py:186} INFO - Started process (PID=878) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:30:37.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:30:37.196+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:30:37.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:30:37.211+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:30:37.208+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:30:37.212+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:30:37.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-01-31T20:31:07.497+0000] {processor.py:186} INFO - Started process (PID=905) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:31:07.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:31:07.502+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:31:07.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:31:07.519+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:31:07.515+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:31:07.520+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:31:07.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.058 seconds
[2025-01-31T20:31:37.799+0000] {processor.py:186} INFO - Started process (PID=932) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:31:37.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:31:37.804+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:31:37.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:31:37.819+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:31:37.814+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:31:37.821+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:31:37.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.056 seconds
[2025-01-31T20:32:07.931+0000] {processor.py:186} INFO - Started process (PID=959) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:32:07.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:32:07.936+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:32:07.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:32:07.951+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:32:07.947+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:32:07.952+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:32:07.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:32:38.133+0000] {processor.py:186} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:32:38.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:32:38.137+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:32:38.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:32:38.151+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:32:38.147+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:32:38.152+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:32:38.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.054 seconds
[2025-01-31T20:33:08.446+0000] {processor.py:186} INFO - Started process (PID=1013) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:33:08.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:33:08.451+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:33:08.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:33:08.464+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:33:08.461+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:33:08.465+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:33:08.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:33:38.808+0000] {processor.py:186} INFO - Started process (PID=1018) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:33:38.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:33:38.813+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:33:38.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:33:38.828+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:33:38.824+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:33:38.831+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:33:38.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.056 seconds
[2025-01-31T20:34:08.971+0000] {processor.py:186} INFO - Started process (PID=1045) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:34:08.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:34:08.975+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:34:08.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:34:08.988+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:34:08.984+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:34:08.989+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:34:09.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:34:39.256+0000] {processor.py:186} INFO - Started process (PID=1072) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:34:39.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:34:39.260+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:34:39.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:34:39.274+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:34:39.270+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:34:39.276+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:34:39.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:35:09.416+0000] {processor.py:186} INFO - Started process (PID=1099) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:35:09.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:35:09.420+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:35:09.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:35:09.434+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:35:09.431+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:35:09.436+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:35:09.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-01-31T20:35:39.526+0000] {processor.py:186} INFO - Started process (PID=1126) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:35:39.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:35:39.531+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:35:39.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:35:39.545+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:35:39.542+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:35:39.547+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:35:39.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-01-31T20:36:09.657+0000] {processor.py:186} INFO - Started process (PID=1153) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:36:09.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:36:09.660+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:36:09.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:36:09.674+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:36:09.670+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:36:09.675+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:36:09.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:36:39.840+0000] {processor.py:186} INFO - Started process (PID=1180) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:36:39.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:36:39.844+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:36:39.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:36:39.858+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:36:39.854+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:36:39.859+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:36:39.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T20:37:10.018+0000] {processor.py:186} INFO - Started process (PID=1207) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:37:10.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:37:10.022+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:37:10.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:37:10.035+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:37:10.032+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:37:10.037+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:37:10.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:37:40.173+0000] {processor.py:186} INFO - Started process (PID=1234) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:37:40.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:37:40.179+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:37:40.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:37:40.195+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:37:40.191+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:37:40.196+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:37:40.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.063 seconds
[2025-01-31T20:38:10.334+0000] {processor.py:186} INFO - Started process (PID=1261) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:38:10.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:38:10.338+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:38:10.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:38:10.351+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:38:10.347+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:38:10.352+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:38:10.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T20:38:40.484+0000] {processor.py:186} INFO - Started process (PID=1288) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:38:40.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:38:40.488+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:38:40.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:38:40.502+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:38:40.498+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:38:40.503+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:38:40.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:39:10.627+0000] {processor.py:186} INFO - Started process (PID=1315) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:39:10.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:39:10.631+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:39:10.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:39:10.645+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:39:10.641+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:39:10.646+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:39:10.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-01-31T20:39:40.726+0000] {processor.py:186} INFO - Started process (PID=1342) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:39:40.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:39:40.731+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:39:40.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:39:40.746+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:39:40.742+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:39:40.748+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:39:40.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.058 seconds
[2025-01-31T20:40:10.965+0000] {processor.py:186} INFO - Started process (PID=1369) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:40:10.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:40:10.969+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:40:10.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:40:10.982+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:40:10.978+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:40:10.982+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:40:11.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T20:40:41.125+0000] {processor.py:186} INFO - Started process (PID=1396) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:40:41.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:40:41.130+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:40:41.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:40:41.145+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:40:41.141+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:40:41.146+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:40:41.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.054 seconds
[2025-01-31T20:41:11.355+0000] {processor.py:186} INFO - Started process (PID=1423) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:41:11.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:41:11.360+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:41:11.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:41:11.372+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:41:11.369+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:41:11.373+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:41:11.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T20:41:41.561+0000] {processor.py:186} INFO - Started process (PID=1450) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:41:41.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:41:41.566+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:41:41.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:41:41.581+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:41:41.577+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:41:41.582+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:41:41.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.058 seconds
[2025-01-31T20:42:11.791+0000] {processor.py:186} INFO - Started process (PID=1477) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:42:11.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:42:11.796+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:42:11.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:42:11.812+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:42:11.808+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:42:11.813+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:42:11.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.074 seconds
[2025-01-31T20:42:42.132+0000] {processor.py:186} INFO - Started process (PID=1504) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:42:42.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:42:42.137+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:42:42.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:42:42.155+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:42:42.149+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:42:42.156+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:42:42.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.060 seconds
[2025-01-31T20:43:12.290+0000] {processor.py:186} INFO - Started process (PID=1531) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:43:12.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:43:12.295+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:43:12.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:43:12.311+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:43:12.307+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:43:12.313+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:43:12.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.057 seconds
[2025-01-31T20:43:42.535+0000] {processor.py:186} INFO - Started process (PID=1558) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:43:42.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:43:42.539+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:43:42.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:43:42.553+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:43:42.549+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:43:42.554+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:43:42.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.054 seconds
[2025-01-31T20:44:12.836+0000] {processor.py:186} INFO - Started process (PID=1585) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:44:12.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:44:12.841+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:44:12.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:44:12.871+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:44:12.862+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:44:12.873+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:44:12.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.107 seconds
[2025-01-31T20:44:43.264+0000] {processor.py:186} INFO - Started process (PID=1612) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:44:43.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:44:43.269+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:44:43.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:44:43.284+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:44:43.281+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:44:43.285+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:44:43.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.058 seconds
[2025-01-31T20:48:16.890+0000] {processor.py:186} INFO - Started process (PID=1642) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:48:16.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:48:16.902+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:48:16.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:48:16.926+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:48:16.919+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:48:16.929+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:48:16.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.112 seconds
[2025-01-31T20:48:48.865+0000] {processor.py:186} INFO - Started process (PID=1669) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:48:48.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:48:48.995+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:48:48.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:48:50.467+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:48:50.024+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:48:50.603+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:48:51.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 3.620 seconds
[2025-01-31T20:51:38.285+0000] {processor.py:186} INFO - Started process (PID=1696) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:51:38.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:51:38.293+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:51:38.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:51:38.319+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:51:38.314+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:51:38.321+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:51:38.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.090 seconds
[2025-01-31T20:52:10.493+0000] {processor.py:186} INFO - Started process (PID=1723) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:52:10.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:52:10.719+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:52:10.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:52:11.312+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:52:11.163+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:52:11.354+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:52:12.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 2.611 seconds
[2025-01-31T20:56:47.686+0000] {processor.py:186} INFO - Started process (PID=1752) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:56:47.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:56:47.694+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:56:47.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:56:47.716+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:56:47.711+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:56:47.718+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:56:48.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.478 seconds
[2025-01-31T20:57:21.397+0000] {processor.py:186} INFO - Started process (PID=1779) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:57:21.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:57:21.872+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:57:21.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:57:23.099+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:57:22.675+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:57:23.267+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:57:25.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 5.404 seconds
[2025-01-31T20:58:16.901+0000] {processor.py:186} INFO - Started process (PID=1806) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:58:16.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:58:16.907+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:58:16.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:58:16.925+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:58:16.920+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:58:16.928+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:58:17.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.729 seconds
[2025-01-31T20:58:52.582+0000] {processor.py:186} INFO - Started process (PID=1833) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T20:58:52.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T20:58:53.183+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:58:53.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:58:55.211+0000] {logging_mixin.py:190} INFO - [2025-01-31T20:58:54.275+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T20:58:55.515+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T20:58:58.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 7.669 seconds
[2025-01-31T21:03:45.577+0000] {processor.py:186} INFO - Started process (PID=1861) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:03:45.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:03:45.619+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:03:45.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:03:45.645+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:03:45.640+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:03:45.647+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:03:45.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.217 seconds
[2025-01-31T21:04:18.188+0000] {processor.py:186} INFO - Started process (PID=1888) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:04:18.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:04:18.407+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:04:18.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:04:20.086+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:04:19.438+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:04:20.146+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:04:22.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 4.875 seconds
[2025-01-31T21:06:12.622+0000] {processor.py:186} INFO - Started process (PID=1917) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:06:12.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:06:12.630+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:06:12.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:06:12.677+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:06:12.667+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:06:12.682+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:06:13.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.591 seconds
[2025-01-31T21:06:43.811+0000] {processor.py:186} INFO - Started process (PID=1945) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:06:43.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:06:43.814+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:06:43.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:06:43.828+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:06:43.825+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:06:43.829+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:06:43.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T21:07:14.049+0000] {processor.py:186} INFO - Started process (PID=1972) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:07:14.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:07:14.053+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:07:14.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:07:14.071+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:07:14.066+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:07:14.072+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:07:14.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.058 seconds
[2025-01-31T21:07:44.176+0000] {processor.py:186} INFO - Started process (PID=1999) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:07:44.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:07:44.220+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:07:44.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:07:44.246+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:07:44.240+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:07:44.247+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:07:44.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.105 seconds
[2025-01-31T21:08:15.224+0000] {processor.py:186} INFO - Started process (PID=2026) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:08:15.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:08:15.229+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:08:15.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:08:15.243+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:08:15.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:08:15.245+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:08:15.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-01-31T21:08:45.330+0000] {processor.py:186} INFO - Started process (PID=2053) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:08:45.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:08:45.335+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:08:45.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:08:45.351+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:08:45.348+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:08:45.352+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:08:45.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.061 seconds
[2025-01-31T21:09:16.342+0000] {processor.py:186} INFO - Started process (PID=2080) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:09:16.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:09:16.346+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:09:16.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:09:16.360+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:09:16.356+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:09:16.361+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:09:16.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.046 seconds
[2025-01-31T21:09:46.451+0000] {processor.py:186} INFO - Started process (PID=2107) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:09:46.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:09:46.455+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:09:46.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:09:46.467+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:09:46.464+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:09:46.468+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:09:46.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T21:10:16.659+0000] {processor.py:186} INFO - Started process (PID=2134) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:10:16.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:10:16.664+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:10:16.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:10:16.680+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:10:16.677+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:10:16.682+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:10:16.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.073 seconds
[2025-01-31T21:10:47.616+0000] {processor.py:186} INFO - Started process (PID=2161) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:10:47.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:10:47.621+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:10:47.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:10:47.636+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:10:47.632+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:10:47.637+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:10:47.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T21:11:17.713+0000] {processor.py:186} INFO - Started process (PID=2188) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:11:17.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:11:17.719+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:11:17.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:11:17.735+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:11:17.730+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:11:17.736+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:11:17.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-01-31T21:11:47.822+0000] {processor.py:186} INFO - Started process (PID=2215) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:11:47.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:11:47.827+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:11:47.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:11:47.840+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:11:47.837+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:11:47.841+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:11:47.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T21:12:18.029+0000] {processor.py:186} INFO - Started process (PID=2242) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:12:18.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:12:18.033+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:12:18.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:12:18.046+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:12:18.043+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:12:18.047+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:12:18.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T21:12:48.112+0000] {processor.py:186} INFO - Started process (PID=2269) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:12:48.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:12:48.119+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:12:48.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:12:48.134+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:12:48.131+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:12:48.136+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:12:48.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-01-31T21:13:18.204+0000] {processor.py:186} INFO - Started process (PID=2296) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:13:18.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:13:18.209+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:13:18.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:13:18.220+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:13:18.217+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:13:18.222+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:13:18.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.047 seconds
[2025-01-31T21:13:48.330+0000] {processor.py:186} INFO - Started process (PID=2323) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:13:48.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:13:48.334+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:13:48.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:13:48.349+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:13:48.346+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:13:48.350+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:13:48.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T21:14:18.491+0000] {processor.py:186} INFO - Started process (PID=2350) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:14:18.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:14:18.497+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:14:18.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:14:18.511+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:14:18.508+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:14:18.512+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:14:18.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T21:14:48.642+0000] {processor.py:186} INFO - Started process (PID=2377) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:14:48.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:14:48.646+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:14:48.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:14:48.661+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:14:48.657+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:14:48.662+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:14:48.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T21:15:28.787+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:15:28.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:15:28.791+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:15:28.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:15:28.806+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:15:28.801+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:15:28.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:15:28.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.056 seconds
[2025-01-31T21:15:59.306+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:15:59.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:15:59.310+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:15:59.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:15:59.324+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:15:59.321+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:15:59.325+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:15:59.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T21:16:29.422+0000] {processor.py:186} INFO - Started process (PID=257) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:16:29.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:16:29.426+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:16:29.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:16:29.437+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:16:29.434+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:16:29.438+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:16:29.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.043 seconds
[2025-01-31T21:16:59.609+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:16:59.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:16:59.614+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:16:59.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:16:59.626+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:16:59.623+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:16:59.627+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:16:59.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T21:17:29.829+0000] {processor.py:186} INFO - Started process (PID=311) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:17:29.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:17:29.834+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:17:29.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:17:29.848+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:17:29.845+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:17:29.849+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:17:29.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T21:18:00.033+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:18:00.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:18:00.037+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:18:00.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:18:00.053+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:18:00.049+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:18:00.054+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:18:00.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.064 seconds
[2025-01-31T21:18:30.294+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:18:30.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:18:30.300+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:18:30.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:18:30.314+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:18:30.311+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:18:30.316+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:18:30.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.056 seconds
[2025-01-31T21:19:00.527+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:19:00.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:19:00.534+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:19:00.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:19:00.552+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:19:00.547+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:19:00.553+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:19:00.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.068 seconds
[2025-01-31T21:19:30.864+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:19:30.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:19:30.869+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:19:30.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:19:30.883+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:19:30.880+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:19:30.885+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:19:30.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.055 seconds
[2025-01-31T21:20:01.087+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:20:01.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:20:01.091+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:20:01.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:20:01.106+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:20:01.101+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:20:01.108+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:20:01.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.055 seconds
[2025-01-31T21:20:31.264+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:20:31.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:20:31.270+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:20:31.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:20:31.287+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:20:31.283+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:20:31.289+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:20:31.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.052 seconds
[2025-01-31T21:21:01.487+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:21:01.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:21:01.491+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:21:01.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:21:01.503+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:21:01.500+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:21:01.504+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:21:01.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.049 seconds
[2025-01-31T21:21:31.571+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:21:31.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:21:31.574+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:21:31.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:21:31.587+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:21:31.583+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:21:31.587+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:21:31.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.053 seconds
[2025-01-31T21:22:01.805+0000] {processor.py:186} INFO - Started process (PID=554) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:22:01.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:22:01.810+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:22:01.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:22:01.825+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:22:01.822+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:22:01.826+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:22:01.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T21:22:32.016+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:22:32.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:22:32.021+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:22:32.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:22:32.034+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:22:32.031+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:22:32.035+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:22:32.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T21:23:02.216+0000] {processor.py:186} INFO - Started process (PID=608) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:23:02.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:23:02.220+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:23:02.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:23:02.233+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:23:02.230+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:23:02.235+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:23:02.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.050 seconds
[2025-01-31T21:23:32.378+0000] {processor.py:186} INFO - Started process (PID=635) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:23:32.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:23:32.382+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:23:32.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:23:32.395+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:23:32.392+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:23:32.396+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:23:32.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.051 seconds
[2025-01-31T21:24:02.566+0000] {processor.py:186} INFO - Started process (PID=662) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:24:02.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:24:02.570+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:24:02.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:24:02.584+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:24:02.581+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:24:02.585+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:24:02.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-01-31T21:24:32.674+0000] {processor.py:186} INFO - Started process (PID=689) to work on /opt/airflow/dags/spark_dag.py
[2025-01-31T21:24:32.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-01-31T21:24:32.679+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:24:32.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:24:32.695+0000] {logging_mixin.py:190} INFO - [2025-01-31T21:24:32.690+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 37, in <module>
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'env': {'JAVA_HOME': '/usr/local/openjdk-11'}}
[2025-01-31T21:24:32.696+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-01-31T21:24:32.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.056 seconds
